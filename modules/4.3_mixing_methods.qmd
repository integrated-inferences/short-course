---
title: "Causal Questions: Population Level"
subtitle: "Mixing Methods"
format: 
   revealjs:
      embed-resources: true
      theme: serif
      slide-level: 3
      slide-number: true
      toc-depth: 2
      show-slide-number: all
      preview-links: auto
      number-sections: true
      link-color: orange
      smaller: true
---

```{r, include = FALSE}
set.seed(1)
library(here)
source(here("assets", "setup.R"))
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```


## A DAG

```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.9\\textwidth'}
par(mar=c(1,1,1,1))
hj_dag(x = c(0, 0, 0, 2, 2, 2, 1, 1, 1),
       y = c(1, 2, 3, 1, 2, 3, 2, 3, 4),
       names = c("X", expression(theta^X), expression(lambda^X), "Y", expression(theta^Y), expression(lambda^Y), "M", expression(theta^M), expression(lambda^M)),
       arcs = cbind( c(3, 2, 1, 5, 6, 7, 8, 9, 1),
                     c(2, 1, 7, 4, 5, 4, 7, 8, 4)),
       padding = .4, contraction = .15)

```

* We'll want to learn about the $\theta$'s and the $\lambda$'s
* We need to observe nodes to learn about other nodes
* We can potentially observe 3 nodes here: $X, M$, and $Y$


## A typical "quantitative" data structure


* Data on exogenous variables and a key outcome for many cases

* E.g., data on inequality ($I$) and democracy ($D$) for many cases


```{r echo=FALSE, out.width="320px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/quantdata.png")
```




## A typical "qualitative" data structure

* Data on exogenous variables and a key outcome plus elements of process for a **small** number of cases

* E.g., data on inequality ($I$), mass mobilization ($M$), and democracy ($D$) for many cases


```{r echo=FALSE, out.width="320px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/qualdata.png")
```


## Mixing qualitative and quantitative

* What if we combine extensive data on many cases with intensive data on a few cases?

```{r echo=FALSE, out.width="320px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/mixeddata.png")
```

* A non-rectangular data structure

* Finite resources $\Rightarrow$ we can't always go "deep" on all cases

## Non-rectangular data

* A data structure that neither standard quantitative nor standard qualitative approaches can handle in a systematic way
* Not a problem for the Integrated Inferences approach
* We simply ask: 
    * Which causal effects in the population are most and least consistent with the data pattern we observe?
* That is, what distribution of causal effects in the population, for each node, are most consistent with this data pattern?
* `CausalQueries` uses information wherever it finds it

## Mixing in practice

For Bayesian approaches this mixing is not hard.

Critically though we maintain the assumption that cases for "in depth" analysis are chosen *at random*---otherwise we have to account for selection processes.


What is the probability of seeing these two cases:

1. $X=1, M = 1, Y = 1$ case 
2. $X=1, Y=1$ (no data on $M$) 

given parameters $\lambda$:

## Mixing in practice

The probability of 1 is:

$$p_{111}= \lambda^X_1 \times (\lambda^M_{01} + \lambda^M_{11}) \times (\lambda^Y_{01} +\lambda^Y_{11})$$

The probability of 2 is:

$$p_{1?1} =  \lambda^X_1\times \left((\lambda^M_{01} + \lambda^M_{11}) \times (\lambda^Y_{01} +\lambda^Y_{11}) + (\lambda^M_{10} + \lambda^M_{00}) \times (\lambda^Y_{10} +\lambda^Y_{11}) \right)$$

So the probability of this data is just:

$$p(D|\lambda) = p_{111} * p_{1?1}$$

## Mixing in practice

Insight:

If we imagine possible parameter values we can figure out the likeihood of *any* data type -- quantitative, qualitative or mixed.

That, with priors, is enough to update:

$$p(\lambda | D) = \frac{p(D | \lambda)p(\lambda)}{p(D)}= \frac{p(D | \lambda)p(\lambda)}{\int_{\lambda'}p(D|\lambda')p(\lambda')d\lambda'}$$


## Why is this useful?

### How qual can inform quant: confounding

```{r, echo = FALSE, fig.width = 9, fig.height = 3,  fig.align = "center"}
model <- make_model("Inequality -> Mobilization -> Democratization; Inequality <-> Democratization")
  model |> plot_model(nodecol = "white", textcol = "black",
                      x_coord = 1:3, y_coord = 3:1) +
  ggplot2::coord_cartesian(clip = "off")
```

Remember:

* Say we just observe a positive Inequality-Democratization correlation
* Could be because Inequality causes Democratization
* Could be because of confounding


### How qual can inform quant: confounding

```{r, echo = FALSE, fig.width = 9, fig.height = 3,  fig.align = "center"}
model <- make_model("Inequality -> Mobilization -> Democratization; Inequality <-> Democratization")
  model |> plot_model(nodecol = "white", textcol = "black",
                      x_coord = 1:3, y_coord = 3:1) +
  ggplot2::coord_cartesian(clip = "off")
```



* Observing $M$ helps
* **Process data helps address the deep problem of confounding**
* Key point: we don't need $M$ for all cases. Can learn from $I$ and $D$ for lots of cases and $M$ for a subset.

### How qual can inform quant: observable confounder

* Another example: $M$ as the confound 

```{r, echo = FALSE, fig.width = 4, fig.height = 3,  fig.align = "center"}

make_model("X->Y <-M->X") |> plot()
```


### How qual can inform quant: observable confounder

* How much can we learn from $M$ data for *some* cases?

```{r, echo = FALSE, fig.width = 4, fig.height = 3,  fig.align = "center"}
knitr::include_graphics("assets/widedeep.png")
```


### How quant can inform qual: getting probative value of a clue from the data

```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.8\\textwidth'}
par(mar=c(1,1,1,1))
hj_dag(x = c(0, 0, 2, 2, 1, 1),
       y = c(1, 2, 1, 2, 1, 2),
       names = c("I", expression(theta^I), "D", expression(theta^D), "M", expression(theta^M)), 
       arcs = cbind( c(2, 1, 4, 6, 5),
                     c(1, 5, 3, 5, 3)),
       padding = .4, contraction = .15)

```

* Suppose we go to the field and we learn that mass mobilization DID occur in Malawi
    * So $M=1$

* What can we conclude?

* NOTHING YET!

### How quant can inform qual: getting probative value of a clue from the data

```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.8\\textwidth'}
par(mar=c(1,1,1,1))
hj_dag(x = c(0, 0, 2, 2, 1, 1),
       y = c(1, 2, 1, 2, 1, 2),
       names = c("I", expression(theta^I), "D", expression(theta^D), "M", expression(theta^M)), 
       arcs = cbind( c(2, 1, 4, 6, 5),
                     c(1, 5, 3, 5, 3)),
       padding = .4, contraction = .15)

```


* The pure process-tracing solution: assign our beliefs about causal effects in the population
    * E.g., beliefs that linked positive effects are more likely than linked negative effects
    * Meaning that $M=1$ in an $I=1, D=1$ case speaks in favor of $I=1$ causing $D=1$
* The mixed-methods solution: **learn** about population-level effects from large-$N$ data


### How quant can inform qual: getting probative value of a clue from the data

* Suppose we have data on $I$, $D$, and $M$ for a large number of cases
* Suppose we observe a strong positive correlation across all 3 variables
* What have we learned, under this model?
    * Positive $I \rightarrow M$ effects more likely than negative
    * Positive $M \rightarrow D$ effects more likely than negative
* So **linked positive effects** more common than linked negative effects
* Meaning that $M=1$ in an $I=1, D=1$ case speaks in favor of $I=1$ causing $D=1$

### How quant can inform qual: getting probative value of a clue from the data

* But now we've now drawn our population-level beliefs **from the data**
* Now, we can go and process-trace
    * Did high inequality cause democratization in Malawi?
    * Observe $M$
* With conclusions grounded in case-level AND population-level evidence


# Example 1: Historical data

*Alan*

## Application from the book: rule-of-law institutions and long-term growth

```{r, echo = FALSE, fig.align='center'}
model <- make_model("Mort -> RoL -> Grth <- Dist; RoL <-> Grth")
  model |> plot_model(labels = c("Distance", "Settler mortality", "Rule of Law", "Growth"), nodecol = "white", textcol = "black",
                      x_coord = c(1, 2, 2, 2), y_coord= c(1, 3,  2,1))
```
* We start with flat priors over causal types
* Gather data on all nodes for many cases

## Rule-of-law and growth: process-tracing probative value from large-$N$ data

```{r echo=FALSE, out.width="300px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/mixingappclue")
```


## Rule-of-law and growth: learning about confounding

* We allowed for confounding between rule of law and growth
    * Mortality's effects on institutions may be correlated with institutions' effects on growth
* We learn about that confounding from the data
    * Rule of law more often has a positive effect on growth where mortality has a negative effect on institutions
* Consistent with selection effects:
    * When mortality is low, settlers make institutional choices in anticipation of their growth effects


## Rule-of-law and growth: learning about confounding

What this looks like in our posteriors over nodal types:

```{r echo=FALSE, out.width="300px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/mixingappconfound")
```

A type where RoL has a positive effect on Growth is more common when Mortality has a negative effect on RoL.

# Example 2: Impact evaluation

*Macartan*

## Development Impact Evaluation Example


* We (WZB team) are working with GIZ to understand the impact of a development intervention.

* The implementers have a "*theory of change*" for how the intervention should work

* We implement a mixed method approach in which we:

  1. Elicit the theory of change *as a DAG* from practitioners and local experts
  2. Gather priors on elements of the theory of change
  3. Coordinate with qualitative researchers to gather information about intermediate nodes on the DAG.
  4. Combine their insights with survey and administrative data to:
     * better understand program effects
     * better understand likely pathways
 
## Development Impact Evaluation Example

```{r}
#| fig-width: 14
#| fig-height: 8
#| echo: false

library(CausalQueries)

model <- make_model(
   
   "
   Marginalization -> Participation; 
   Marginalization -> Understanding; 
   Marginalization -> Inclusion; 
   Marginalization -> Connections; 
   Invitation -> Participation; 
   Municipality -> Participation; 
   Municipality -> Understanding; 
   Municipality -> Inclusion; 
   Municipality -> Connections; 
   Participation -> Understanding; 
   Participation -> Connections; 
   Participation -> Inclusion; 
   Project -> Inclusion; 
   Project -> Understanding;
   Inclusion  -> Trust;
   Understanding  -> Trust;
   Connections  -> Trust"
 , add_causal_types = FALSE)

labels <- list(
  Invitation    = "Invitation\nto intervention",
  Marginalization  = "Locally\nMarginalized",
  Municipality  = "Municipality \n quality",
  Participation = "Participates",
  Understanding = "Believes municipality\neffective",
  Connections   = "Is connected \n(has access)",
  Inclusion     = "Feels\nrepresented",
  Project   = "Project\nInterruptions",
  Trust         = "Trust in local government and governance"
)

# 
# a check on labels
labels_vec <- function(model, labels) {
  nodes   <- model$nodes
  missing <- setdiff(nodes, names(labels))
  extra   <- setdiff(names(labels), nodes)
  if (length(missing)) stop("Fehlende Labels für: ", paste(missing, collapse = ", "))
  if (length(extra))   warning("Ignoriere nicht verwendete Labels: ", paste(extra, collapse = ", "))
  unname(labels[match(nodes, names(labels))])
}

labs_in_order <- labels_vec(model, labels)

dag_coords <- data.frame(
  node = c(
    "Invitation",
    "Marginalization",
    "Municipality",
    "Project",
    "Participation",
    "Connections",
    "Inclusion",
    "Understanding",
    "Trust"
  ),
  y = c(5.2, 5.0, 5.0, 2.5, 4.2, 2.0, 2.0, 2.0, 0.5),
  x = c(2.0, 1.0, 3.0, 2.5, 2.0, 0.5, 2.0, 3.5, 2.0),
  stringsAsFactors = FALSE
)


plot(
  model,
  x_coord = dag_coords$x,
  y_coord = dag_coords$y,
  nodecol = "white",
  textcol = "black",
  labels  = labs_in_order
)


```


## Use of prior data

Priors are then used to implement four analyses:


* causal queries implied by uniform priors  
* causal queries implied by stakeholder priors  
* posterior values of causal queries using a model in which data and uniform priors are used
* posterior values of causal queries using a model in which data and stakeholder priors are used

## Priors form

```{r echo=FALSE, fig.align="center", eval = TRUE}
knitr::include_graphics("assets/priors_question.jpg")
```


## Qualitative data form


```{r echo=FALSE, fig.align="center", eval = TRUE}
knitr::include_graphics("assets/qual_form.jpg")
```


## Updating on sub-DAGs


```{r}
#| fig-width: 12
#| fig-height: 9
#| echo: false


model <- make_model(
   
   "
   Marginalization -> Participation; 
   Marginalization -> Inclusion; 
   Invitation -> Participation; 
   Municipality -> Participation; 
   Municipality -> Inclusion; 
   Participation -> Inclusion"
 , add_causal_types = FALSE)

labels <- list(
  Invitation    = "Invitation\nto intervention",
  Marginalization  = "Locally\nMarginalized",
  Municipality  = "Municipality \n quality",
  Participation = "Participates",
  Inclusion     = "Feels\nrepresented"
)

# 
# a check on labels
labels_vec <- function(model, labels) {
  nodes   <- model$nodes
  missing <- setdiff(nodes, names(labels))
  extra   <- setdiff(names(labels), nodes)
  if (length(missing)) stop("Fehlende Labels für: ", paste(missing, collapse = ", "))
  if (length(extra))   warning("Ignoriere nicht verwendete Labels: ", paste(extra, collapse = ", "))
  unname(labels[match(nodes, names(labels))])
}

labs_in_order <- labels_vec(model, labels)

plot(
  model,
  x_coord = c(2,1,3,2,2),
  y_coord = c(3,3,3,2,1),
  nodecol = "white",
  textcol = "black",
  labels  = labs_in_order
)


```
