---
title: "Causal Questions: Population Level"
subtitle: "Intuition"
format: 
   revealjs:
      embed-resources: true
      theme: serif
      slide-level: 3
      slide-number: true
      toc-depth: 2
      show-slide-number: all
      preview-links: auto
      number-sections: true
      link-color: orange
      smaller: true
---

```{r, include = FALSE}
set.seed(1)
library(knitr)
source("assets/setup.R")
knitr::opts_chunk$set(echo = TRUE)
```

## How will we answer questions about populations?

* We need to learn about those $\lambda$'s
    * About the proportions of the population with different kinds of causal effects
* We will have *prior* beliefs about those proportions
* Then, when we see data on lots of cases, we will **update** our beliefs about proportions
    * From a prior distribution over $\lambda$ $\Rightarrow$ a posterior distribution over $\lambda$



## How do we "update" our models?

* We've talked about process tracing a single case to answer a case-level query
    * Here the model is fixed
    * We use the model + case data to answer questions about the case
* We can also use data to "update" our models
    * Use data on many cases to learn about causal effects in the population
* Allows mixing methods: using data on lots of cases, we can learn about probative value of process-tracing evidence
* The core logic: we learn by **updating population-level causal beliefs toward beliefs more consistent with the data**


## Start with a DAG

```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.9\\textwidth'}
par(mar=c(1,1,1,1))
hj_dag(x = c(0, 0, 0, 2, 2, 2, 1, 1, 1),
       y = c(1, 2, 3, 1, 2, 3, 1, 2, 3),
       names = c("I", expression(theta^I), expression(lambda^I), "D", expression(theta^D), expression(lambda^D), "M", expression(theta^M), expression(lambda^M)),
       arcs = cbind( c(3, 2, 1, 5, 6, 7, 8, 9),
                     c(2, 1, 7, 4, 5, 4, 7, 8)),
       padding = .4, contraction = .15)

```


## Large-$N$ estimation of $ATE$: what happens to beliefs over parameters

* Say we only collect data on $I$, $M$, and $D$ for a large number of cases
* We update on $\lambda^I$ , $\lambda^M$ and $\lambda^D$ to place more weight on values that are likely to give rise to the pattern of data we see
* We will come to put more weight on a *joint distribution* of $\lambda^M$ and $\lambda^D$ in line with the data and less posterior weight on all other combinations

**Question**: What would you infer if you saw a very high correlation between $I$ and $D$ and a *low* correlation between $I$ and $M$? Or a low correlation between $M$ and $D$?


## General procedure

Key insight: 

* If we *suppose* a given set of  parameter values, we can figure out the likelihood of the data given those values.
* We can do this for all possible parameter values and see which ones are more in line with the data


That, with priors, is enough to update:

$$p(\lambda | D) = \frac{p(D | \lambda)p(\lambda)}{p(D)}$$

## Illustration of 'manual' updating

Let's update manually.

### Causal inference on a grid

Consider this joint distribution with binary $X$ and binary $Y$ from [here](https://macartan.github.io/ci/ci_2025.html#/example-without-identification-2)

|     | Y = 0 | Y = 1 | 
|-----|-------|-------|
| **X = 0** | $\lambda_{01}/2 + \lambda_{00}/2$      |  $\lambda_{10}/2 + \lambda_{11}/2$     |   
| **X = 1** | $\lambda_{10}/2 + \lambda_{00}/2$      |  $\lambda_{01}/2 + \lambda_{11}/2$     |   


reminder: $\lambda_{10}$ is share with negative effects, $\lambda_{01}$ is share with positive effects...

### Causal inference on a grid: strategy

Say we now had (finite) data filling out this table. What posteriors should we form over $\lambda_{10},\lambda_{01},\lambda_{00},\lambda_{11}$?


|     | Y = 0 | Y = 1 | 
|-----|-------|-------|
| **X = 0** | $n_{00}$      |  $n_{01}$     |   
| **X = 1** | $n_{10}$      |  $n_{11}$     |   

Lets start with a flat prior over the shares and then update over possible shares based on the data.

This time we will start with a draw of possible shares and put look for posterior weights on each drawn share.


### Causal inference on a grid: likelihood {.smaller}

$$
\Pr(n_{00}, n_{01}, n_{10}, n_{11} \mid \lambda_{10},\lambda_{01},\lambda_{00},\lambda_{11}) =
f_{\text{multinomial}}\left( \alpha_{00}, \alpha_{01}, \alpha_{10}, \alpha_{11} \mid \sum n, w \right)
$$
where:

$$w = \left(\frac12(\lambda_{01} + \lambda_{00}),  \frac12(\lambda_{10}+\lambda_{11}), \frac12(\lambda_{10}+\lambda_{00}), \frac12(\lambda_{01}+\lambda_{11})\right)$$
The weights are just the probability of each data type, given $\lambda$.

why multinomial?

### Causal inference on a grid: execution {.smaller}

prior draw with 10000 possibilities:

```{r}

x <- gtools::rdirichlet(10000, alpha = c(1,1,1,1)) |> 
  as.data.frame()

names(x) <- letters[1:4]

x |> head() |> kable(digits = 3)
```

* we are using $a,b,c,d$ labels for $\lambda_{10}, \lambda_{01}, \lambda_{00}, \lambda_{11}$
* we are using a handy distribution: the *Dirichlet distribution* 
* each row sums to 1 (each point (row) lies on a simplex)

### Causal inference on a grid: execution {.smaller}


Imagine we had data (number of units with given values of X and Y):

$$n_{00} = 400, n_{01} = 100, n_{10} = 100, n_{11} = 400$$

Difference in means = 0.6. 

Then we update (if we do it manually!) like this:


```{r}
# add likelihood and calculate posterior

x <- x |> 
  rowwise() |>  # Ensures row-wise operations
  mutate(
    likelihood = dmultinom(
      c(400, 100, 100, 400),
      prob = c(b + c, a + c, a + d, b + d) / 2
    )
  ) |> 
  ungroup() |>
  mutate(posterior = likelihood / sum(likelihood))

```


### Causal inference on a grid: execution {.smaller}

```{r, echo = FALSE}
x |> 
  mutate(likelihood = formatC(likelihood, format = "e", digits = 2),
         posterior = formatC(posterior, format = "e", digits = 2)) |> 
  head() |>
  kable(digits = 2)
```

### Causal inference on a grid: inferences

We calculate queries like this:

```{r}
x |> summarize(a = weighted.mean(a, posterior),
               b = weighted.mean(b, posterior),
               ATE = b - a) |>
  kable(digits = 2)
```

### Causal inference on a grid: inferences

```{r, fig.cap = "Spot the ridge"}
x |> ggplot(aes(b, a, size = posterior)) + geom_point(alpha = .5) 

```


## In sum: learning from data

* For any data pattern, we gain confidence in parameter values more consistent with the data
* For single-case inference, we must bring background beliefs about population-level causal effects
* For multiple cases, we can learn about effects from the data
* Large-$N$ data can thus provide probative value for small-$N$ process-tracing
* All inference is conditional on the model


