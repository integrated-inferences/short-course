---
title: "Causal Questions: Population Level"
subtitle: "Intuition"
format: 
   revealjs:
      embed-resources: true
      theme: serif
      slide-level: 3
      slide-number: true
      toc-depth: 2
      show-slide-number: all
      preview-links: auto
      number-sections: true
      link-color: orange
      smaller: true
---

```{r, include = FALSE}
set.seed(1)
library(knitr)
source("assets/setup.R")
knitr::opts_chunk$set(echo = TRUE)
```


## How do we "update" our models?

* We've talked about process tracing a single case to answer a case-level query
    * Here the model is fixed
    * We use the model + case data to answer questions about the case
* We can also use data to "update" our models
    * Use data on many cases to learn about causal effects in the population
* Allows mixing methods: using data on lots of cases, we can learn about probative value of process-tracing evidence
* The core logic: we learn by **updating population-level causal beliefs toward beliefs more consistent with the data**


## Start with a DAG

```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.9\\textwidth'}
par(mar=c(1,1,1,1))
hj_dag(x = c(0, 0, 2, 2),
       y = c(1, 2, 1, 2),
       names = c(expression(paste(I)),
                 expression(paste(theta^I)),
                expression(paste(D)),
                expression(paste(theta^D))),
       arcs = cbind( c(2, 1, 4),
                     c(1, 3, 3)),
       padding = .4, contraction = .15) 

```

## Large-$N$ estimation of $ATE$: basic intuition

* The most straightforward
* Suppose we collect data on $I$ and $D$ for a large number of cases
* We observe a strong positive correlation 
* We will think there's a positive average effect
    * Note: this specific model rules out confounding
    * All exogenous nodes are independently assigned 
        * We will complicate this later



## Now, complicate the DAG

```{r, echo = FALSE, fig.width = 5, fig.height = 3,  fig.align="center", out.width='.9\\textwidth'}
par(mar=c(1,1,1,1))
hj_dag(x = c(0, 0, 0, 2, 2, 2, 1, 1, 1),
       y = c(1, 2, 3, 1, 2, 3, 1, 2, 3),
       names = c("I", expression(theta^I), expression(lambda^I), "D", expression(theta^D), expression(lambda^D), "M", expression(theta^M), expression(lambda^M)),
       arcs = cbind( c(3, 2, 1, 5, 6, 7, 8, 9),
                     c(2, 1, 7, 4, 5, 4, 7, 8)),
       padding = .4, contraction = .15)

```


## Large-$N$ estimation of $ATE$: what happens to beliefs over parameters

* Again, we collect data on $I$ and $D$ for a large number of cases
* We observe a strong positive correlation 
* We will think there's a positive average effect



## Large-$N$ estimation of $ATE$: what happens to beliefs over parameters

* Now, we will update on both $\lambda^M$ and $\lambda^D$
* An $I \rightarrow D$ effect can only happen if $I$ affects $M$ and $M$ affects $D$, in specific ways
* Two possible **combinations** of effects can generate a positive $I \rightarrow D$ effect
    * $I \rightarrow M$ is positive, $M \rightarrow D$ is positive
    * $I \rightarrow M$ is negative, $M \rightarrow D$ is negative
* So we will come to put more weight on a *joint distribution* of $\lambda^M$ and $\lambda^D$ in which there are lots of cases with one of these two combinations
* ...and less posterior weight on all other combinations of effects



## Learning with confounding

```{r echo=FALSE, out.width="300px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/confounding.png")
```

* Say we just observe a positive Inequality-Democratization correlation
* Could be because Inequality causes Democratization
* Could be because of confounding


## Learning with confounding

```{r echo=FALSE, out.width="300px", fig.align="center", eval = TRUE}
knitr::include_graphics("assets/confounding.png")
```

* So observing $M$ helps!
    * Allows us to learn if $I$ affects $M$
    * And if $M$ affects $D$
* Suppose we see:
    * a strong positive $I$ to $M$ correlation
    * a strong positive $M$ to $D$ correlation
* We update toward belief that $I$ to $D$ effect is common, and that confounding is uncommon
* If $I/M$ and $M/D$ correlations are weak/absent, then confounding likely
* **Process data helps address the deep problem of confounding**


<!-- ## Integration qual and quant: getting our probative value from the data -->

<!-- * Suppose we have data on $I$, D$, **and $M$** for a large number of cases -->
<!-- * We observe a strong positive correlation across all 3 variables -->
<!-- * What have we learned, under this model? -->
<!--     * Positive $I \rightarrow M$ effects more likely than negative -->
<!--     * Positive $M \rightarrow D$ effects more likely than negative -->
<!-- * Given the model, we've now drawn our population-level beliefs **from the data** -->
<!-- * Now, we go and process-trace -->
<!--     * Did high inequality cause democratization in Malawi? -->
<!--     * Observe $M$ -->
<!-- * Now, we have population-beliefs that give $M$ probative value -->

## In sum: learning from data

* For any data pattern, we gain confience in parameter values more consistent with the data
* For single-case inference, we must bring background beliefs about population-level causal effects
* For multiple cases, we can learn about effects from the data
* Large-$N$ data can thus provide probative value for small-$N$ process-tracing
* All inference is conditional on the model





